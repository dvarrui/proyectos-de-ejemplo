
# Ruby scrapping

Enlaces de interés:
* https://www.scrapingbee.com/blog/web-scraping-ruby/
* https://www.webscrapingapi.com/ruby-web-scraping/

Páginas web estáticas
* nokogiri (parsing gem), HTTParty (HTTP request gem)
* Standard library: open-uri, net/http, and csv.
* Clients: Net::HTTP
* Parse Nokogiri: access DOM elements.
* Capybara to execute interactive actions, typically performed by users (e.g. mouse clicks).

Páginas web dinámicas
* A complete Ruby web scraping framework
* tools which specifically support JavaScript-powered sites
* Scrape dynamic pages.

Install tools:
- Chrome and Firefox: brew cask install google-chrome firefox
- ChromeDriver: brew cask install chromedriver
- geckodriver: brew install geckodriver
- PhantomJS: brew install phantomjs
- Kimurai gem: gem install kimurai


# tools

* Watir: a Selenium powered gem used for automatic testing, as it can imitate user's behavior on a browser.
* Webdrivers: automatically download thelatest driver for a browser instance.
* Nokogiri: make web pages analysis easy. It can parse HTML, XML, detects broken HTML documents, and offers access to elements by XPath and CSS3 selectors.
